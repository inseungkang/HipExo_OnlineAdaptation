{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from scipy.signal import find_peaks, peak_prominences, peak_widths\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "columns = ['lJPos', 'rJPos', 'lJVel', 'rJVel', 'lJTorque', 'rJTorque',\n",
    "           'eulerX', 'eulerY', 'eulerZ', 'gyroX', 'gyroY', 'gyroZ', 'accX', 'accY', 'accZ',\n",
    "           'batt', 'cpu', 'mem', 'lBttn', 'rBttn', 'time', 'lJVelFilt', 'rJVelFilt',\n",
    "           'lJPosReset', 'rJPosReset', 'lGC', 'rGC', 'stand', 'lCmdTorque', 'rCmdTorque',\n",
    "           'lRecvTorque', 'rRecvTorque', 'lStanceSwing', 'rStanceSwing', 'nWalk', 'lWalk', 'rWalk', 'none']\n",
    "\n",
    "ST_columns = ['lJPos', 'rJPos', 'lJVel', 'rJVel', 'lJTorque', 'rJTorque',\n",
    "           'eulerX', 'eulerY', 'eulerZ', 'gyroX', 'gyroY', 'gyroZ', 'accX', 'accY', 'accZ',\n",
    "           'lBttn', 'rBttn', 'time', 'lJVelFilt', 'rJVelFilt',\n",
    "           'lJPosReset', 'rJPosReset', 'lGC', 'rGC', 'stand', 'lCmdTorque', 'rCmdTorque',\n",
    "           'lRecvTorque', 'rRecvTorque', 'lStanceSwing', 'rStanceSwing', 'nWalk', 'lWalk', 'rWalk', 'none']\n",
    "\n",
    "channel = ['lJPos', 'rJPos', 'lJVel', 'rJVel', 'gyroX', 'gyroY', 'gyroZ', 'accX', 'accY', 'accZ', 'lWalk', 'rWalk']\n",
    "    \n",
    "def find_peak_idx(joint_positions):\n",
    "    peaks, _ = find_peaks(joint_positions)\n",
    "    prominences = peak_prominences(joint_positions, peaks)[0]\n",
    "    maximas, _ = find_peaks(joint_positions, prominence=np.median(prominences)+np.var(prominences), distance=150)\n",
    "    return maximas\n",
    "\n",
    "def label_ground_truth(joint_positions):\n",
    "    maximas = find_peak_idx(joint_positions)\n",
    "    maximas = np.append(0, maximas)\n",
    "    end_idx = maximas[-1]\n",
    "    \n",
    "    y = pd.Series(np.nan, index=range(0, joint_positions.shape[0]))  \n",
    "    for maxima in maximas:\n",
    "        y[maxima] = 1\n",
    "        y[maxima+1] = 0\n",
    "    y.interpolate(inplace=True)\n",
    "    y.fillna(0, inplace=True)\n",
    "    y_theta = y * 2 * np.pi\n",
    "    \n",
    "    cartesian_output = np.stack([np.cos(y_theta), np.sin(y_theta)], axis=1)\n",
    "    return y, end_idx, cartesian_output\n",
    "\n",
    "def custom_rmse(y_true, y_pred):\n",
    "    #Raw values and Prediction are in X,Y\n",
    "    labels, theta, gp = {}, {}, {}\n",
    "\n",
    "    #Separate legs\n",
    "    left_true = y_true[:, :2]\n",
    "    right_true = y_true[:, 2:]\n",
    "    left_pred = y_pred[:, :2]\n",
    "    right_pred = y_pred[:, 2:]\n",
    "    \n",
    "    #Calculate cosine distance\n",
    "    left_num = np.sum(np.multiply(left_true, left_pred), axis=1)\n",
    "    left_denom = np.linalg.norm(left_true, axis=1) * np.linalg.norm(left_pred, axis=1)\n",
    "    right_num = np.sum(np.multiply(right_true, right_pred), axis=1)\n",
    "    right_denom = np.linalg.norm(right_true, axis=1) * np.linalg.norm(right_pred, axis=1)\n",
    "\n",
    "    left_cos = left_num / left_denom\n",
    "    right_cos = right_num / right_denom\n",
    "    \n",
    "    #Clip large values and small values\n",
    "    left_cos = np.minimum(left_cos, np.zeros(left_cos.shape)+1)\n",
    "    left_cos = np.maximum(left_cos, np.zeros(left_cos.shape)-1)\n",
    "    \n",
    "    right_cos = np.minimum(right_cos, np.zeros(right_cos.shape)+1)\n",
    "    right_cos = np.maximum(right_cos, np.zeros(right_cos.shape)-1)\n",
    "    \n",
    "    # What if denominator is zero (model predicts 0 for both X and Y)\n",
    "    left_cos[np.isnan(left_cos)] = 0\n",
    "    right_cos[np.isnan(right_cos)] = 0\n",
    "    \n",
    "    #Get theta error\n",
    "    left_theta = np.arccos(left_cos)\n",
    "    right_theta = np.arccos(right_cos)\n",
    "    \n",
    "    #Get gait phase error\n",
    "    left_gp_error = left_theta * 100 / (2*np.pi)\n",
    "    right_gp_error = right_theta * 100 / (2*np.pi)\n",
    "    \n",
    "    #Get rmse\n",
    "    left_rmse = np.sqrt(np.mean(np.square(left_gp_error)))\n",
    "    right_rmse = np.sqrt(np.mean(np.square(right_gp_error)))\n",
    "\n",
    "    #Separate legs\n",
    "    labels['left_true'] = left_true\n",
    "    labels['right_true'] = right_true\n",
    "    labels['left_pred'] = left_pred\n",
    "    labels['right_pred'] = right_pred\n",
    "\n",
    "    for key, value in labels.items(): \n",
    "        #Convert to polar\n",
    "        theta[key] = np.arctan2(value[:, 1], value[:, 0])\n",
    "        \n",
    "        #Bring into range of 0 to 2pi\n",
    "        theta[key] = np.mod(theta[key] + 2*np.pi, 2*np.pi)\n",
    "\n",
    "        #Interpolate from 0 to 100%\n",
    "        gp[key] = 100*theta[key] / (2*np.pi)\n",
    "\n",
    "    return left_rmse, right_rmse\n",
    "\n",
    "def custom_rmse_uni(left_true, left_pred):\n",
    "    #Raw values and Prediction are in X,Y\n",
    "    labels, theta, gp = {}, {}, {}\n",
    "    \n",
    "    #Calculate cosine distance\n",
    "    left_num = np.sum(np.multiply(left_true, left_pred), axis=1)\n",
    "    left_denom = np.linalg.norm(left_true, axis=1) * np.linalg.norm(left_pred, axis=1)\n",
    "\n",
    "    left_cos = left_num / left_denom\n",
    "    \n",
    "    #Clip large values and small values\n",
    "    left_cos = np.minimum(left_cos, np.zeros(left_cos.shape)+1)\n",
    "    left_cos = np.maximum(left_cos, np.zeros(left_cos.shape)-1)\n",
    "    \n",
    "    # What if denominator is zero (model predicts 0 for both X and Y)\n",
    "    left_cos[np.isnan(left_cos)] = 0\n",
    "    \n",
    "    #Get theta error\n",
    "    left_theta = np.arccos(left_cos)\n",
    "    \n",
    "    #Get gait phase error\n",
    "    left_gp_error = left_theta * 100 / (2*np.pi)\n",
    "    \n",
    "    #Get rmse\n",
    "    left_rmse = np.sqrt(np.mean(np.square(left_gp_error)))\n",
    "\n",
    "    #Separate legs\n",
    "    labels['left_true'] = left_true\n",
    "    labels['left_pred'] = left_pred\n",
    "\n",
    "    for key, value in labels.items(): \n",
    "        #Convert to polar\n",
    "        theta[key] = np.arctan2(value[:, 1], value[:, 0])\n",
    "        \n",
    "        #Bring into range of 0 to 2pi\n",
    "        theta[key] = np.mod(theta[key] + 2*np.pi, 2*np.pi)\n",
    "\n",
    "        #Interpolate from 0 to 100%\n",
    "        gp[key] = 100*theta[key] / (2*np.pi)\n",
    "\n",
    "    return left_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30528, 12) (7633, 12)\n",
      "WARNING:tensorflow:From /Applications/miniconda3/envs/epic/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Applications/miniconda3/envs/epic/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#-- Load model & OA data --#\n",
    "\n",
    "# for file_path in glob.glob(f'data/raw/AB08_CCW_BT.txt'):\n",
    "for file_path in glob.glob(f'data/OA_TEST_OVERGROUND.txt'):\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=1)\n",
    "    data.columns = ST_columns\n",
    "    input_data = pd.DataFrame(data, columns=channel).to_numpy()\n",
    "\n",
    "input_data, eval_data = input_data[:int(input_data.shape[0]*0.8), :], input_data[int(input_data.shape[0]*0.8):, :]\n",
    "\n",
    "print(input_data.shape, eval_data.shape)\n",
    "# data = data.to_numpy()\n",
    "# input_data = data[:,:-1]\n",
    "# print(input_data)\n",
    "# plt.plot(input_data[:2000,-1])\n",
    "# plt.plot(input_data[:2000,-2])\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "model_adap_left = tf.keras.models.load_model('GP_Left_WS80_noBN.h5')\n",
    "model_stat_left = tf.keras.models.load_model('GP_Left_WS80_noBN.h5')\n",
    "\n",
    "# model_adap_right = keras.models.load_model('final_model_right_WS80.h5')\n",
    "# model_stat_right = keras.models.load_model('final_model_right_WS80.h5')\n",
    "\n",
    "# model_adap_left.summary()\n",
    "# for layer in model_adap_left.layers[:8]:\n",
    "#     layer.trainable = False\n",
    "#     print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Configs --#\n",
    "\n",
    "window_size = 80\n",
    "channel_number = 12\n",
    "buffer_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7313, 80, 10) (7313, 2)\n"
     ]
    }
   ],
   "source": [
    "#-- Process Eval Data --#\n",
    "\n",
    "peak_idx = find_peak_idx(eval_data[:,0])[-1]\n",
    "eval_l_gp = eval_data[:,-2] \n",
    "eval_x = eval_data[:,:-2]\n",
    "\n",
    "eval_gait_phase, end_idx, eval_y = label_ground_truth(eval_x[:,0])\n",
    "eval_x = eval_x[:end_idx,:]\n",
    "eval_y = eval_y[:end_idx,:]      \n",
    "eval_gait_phase = eval_gait_phase[:end_idx]\n",
    "eval_l_gp = eval_l_gp[:end_idx]\n",
    "\n",
    "\n",
    "shape = (eval_x.shape[0] - window_size + 1, window_size, eval_x.shape[1])\n",
    "strides = (eval_x.strides[0], eval_x.strides[0], eval_x.strides[1])\n",
    "eval_x = np.lib.stride_tricks.as_strided(eval_x, shape=shape, strides=strides)\n",
    "eval_y = eval_y[window_size - 1:]\n",
    "\n",
    "print(eval_x.shape, eval_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Eval RMSE: Static(7.74) | Adap (7.74)\n",
      "Training RMSE: (27.05) | (26.39) -- Eval RMSE: (7.74) | (5.88)\n",
      "Training RMSE: (9.54) | (4.01) -- Eval RMSE: (7.74) | (3.75)\n",
      "Training RMSE: (9.71) | (3.11) -- Eval RMSE: (7.74) | (3.37)\n",
      "Training RMSE: (8.26) | (2.03) -- Eval RMSE: (7.74) | (2.81)\n",
      "Training RMSE: (8.72) | (1.58) -- Eval RMSE: (7.74) | (1.95)\n",
      "Training RMSE: (6.99) | (1.88) -- Eval RMSE: (7.74) | (2.11)\n",
      "Training RMSE: (7.32) | (1.67) -- Eval RMSE: (7.74) | (2.05)\n",
      "Training RMSE: (6.84) | (1.69) -- Eval RMSE: (7.74) | (2.26)\n",
      "Training RMSE: (6.98) | (1.48) -- Eval RMSE: (7.74) | (1.72)\n",
      "Training RMSE: (9.69) | (1.75) -- Eval RMSE: (7.74) | (1.88)\n",
      "Training RMSE: (7.66) | (1.49) -- Eval RMSE: (7.74) | (1.47)\n",
      "Training RMSE: (6.76) | (1.56) -- Eval RMSE: (7.74) | (1.91)\n",
      "Training RMSE: (8.29) | (1.52) -- Eval RMSE: (7.74) | (1.91)\n",
      "Training RMSE: (8.04) | (1.46) -- Eval RMSE: (7.74) | (1.69)\n",
      "Training RMSE: (9.67) | (1.45) -- Eval RMSE: (7.74) | (1.57)\n",
      "Training RMSE: (4.44) | (1.50) -- Eval RMSE: (7.74) | (1.80)\n",
      "Training RMSE: (4.59) | (1.26) -- Eval RMSE: (7.74) | (1.46)\n",
      "Training RMSE: (4.83) | (1.37) -- Eval RMSE: (7.74) | (1.95)\n",
      "Training RMSE: (4.70) | (1.63) -- Eval RMSE: (7.74) | (2.11)\n",
      "Training RMSE: (5.42) | (1.03) -- Eval RMSE: (7.74) | (1.73)\n",
      "Training RMSE: (6.28) | (1.13) -- Eval RMSE: (7.74) | (1.73)\n",
      "Training RMSE: (7.57) | (1.28) -- Eval RMSE: (7.74) | (1.61)\n",
      "Training RMSE: (10.32) | (1.11) -- Eval RMSE: (7.74) | (1.89)\n",
      "Training RMSE: (11.28) | (1.34) -- Eval RMSE: (7.74) | (2.00)\n",
      "Training RMSE: (8.97) | (1.15) -- Eval RMSE: (7.74) | (1.74)\n",
      "Training RMSE: (12.27) | (1.13) -- Eval RMSE: (7.74) | (1.75)\n",
      "Training RMSE: (8.93) | (1.19) -- Eval RMSE: (7.74) | (1.69)\n",
      "Training RMSE: (12.76) | (1.68) -- Eval RMSE: (7.74) | (1.63)\n",
      "Training RMSE: (10.81) | (1.41) -- Eval RMSE: (7.74) | (1.48)\n",
      "Training RMSE: (9.44) | (1.12) -- Eval RMSE: (7.74) | (1.42)\n"
     ]
    }
   ],
   "source": [
    "#-- OA --#\n",
    "\n",
    "y_new_eval = model_stat_left.predict(eval_x)\n",
    "y_old_eval = model_adap_left.predict(eval_x)\n",
    "\n",
    "eval_rmse_o = custom_rmse_uni(eval_y, y_old_eval)\n",
    "eval_rmse_n = custom_rmse_uni(eval_y, y_new_eval)\n",
    "\n",
    "print(f'Starting Eval RMSE: Static({eval_rmse_o:.2f}) | Adap ({eval_rmse_n:.2f})')\n",
    "\n",
    "old_buffer = np.empty((0, channel_number))\n",
    "current_buffer = np.empty((0, channel_number))\n",
    "\n",
    "for ii, stream_vec in enumerate(input_data):\n",
    "\n",
    "    stream_vec = np.expand_dims(stream_vec, axis=0)\n",
    "    current_buffer = np.concatenate([current_buffer, stream_vec], axis=0)\n",
    "        \n",
    "    if current_buffer.shape[0] == buffer_size:\n",
    "        peak_idx = find_peak_idx(current_buffer[:,0])[-1]\n",
    "        x = np.concatenate([old_buffer, current_buffer[:peak_idx, :]], axis=0)\n",
    "        l_mode = x[:,-2] \n",
    "        x = x[:,:-2]\n",
    "\n",
    "        gait_phase, end_idx, y = label_ground_truth(x[:,0])\n",
    "        x = x[:end_idx,:]\n",
    "        y = y[:end_idx,:]      \n",
    "        gait_phase = gait_phase[:end_idx]\n",
    "        l_mode = l_mode[:end_idx]\n",
    "        \n",
    "#         new_idx = np.where((l_mode != 0))[0].tolist()\n",
    "#         x = x[new_idx,:]\n",
    "#         y = y[new_idx,:]\n",
    "#         gait_phase = gait_phase[new_idx]\n",
    "#         l_mode = l_mode[new_idx]\n",
    "        \n",
    "#         plt.plot(x[:,0])\n",
    "#         plt.plot(gait_phase)\n",
    "#         plt.plot(l_mode)\n",
    "#         plt.show()\n",
    "\n",
    "        window_size = 80\n",
    "        shape = (x.shape[0] - window_size + 1, window_size, x.shape[1])\n",
    "        strides = (x.strides[0], x.strides[0], x.strides[1])\n",
    "        x = np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)\n",
    "        y = y[window_size - 1:]\n",
    "#         y = np.expand_dims(y[window_size - 1:], axis=1)\n",
    "        \n",
    "        model_adap_left.fit(x, y, epochs=1, batch_size=256, verbose=0)\n",
    "\n",
    "        y_new_train = model_adap_left.predict(x)\n",
    "        y_old_train = model_stat_left.predict(x)\n",
    "#         y = np.squeeze(y, axis=1)\n",
    "\n",
    "        left_rmse_o = custom_rmse_uni(y, y_old_train)\n",
    "        left_rmse_n = custom_rmse_uni(y, y_new_train)\n",
    "        \n",
    "        y_new_eval = model_adap_left.predict(eval_x)\n",
    "        y_old_eval = model_stat_left.predict(eval_x)\n",
    "        \n",
    "        eval_rmse_o = custom_rmse_uni(eval_y, y_old_eval)\n",
    "        eval_rmse_n = custom_rmse_uni(eval_y, y_new_eval)\n",
    "        \n",
    "        print(f\"Training RMSE: ({left_rmse_o:.2f}) | ({left_rmse_n:.2f}) -- Eval RMSE: ({eval_rmse_o:.2f}) | ({eval_rmse_n:.2f})\")\n",
    "        \n",
    "#         plt.plot(y[:,1])\n",
    "#         plt.plot(y_old_test[:,1])\n",
    "#         plt.plot(y_new_test[:,1])\n",
    "#         plt.show()\n",
    "        \n",
    "        old_buffer = current_buffer[peak_idx:, :]\n",
    "        current_buffer = np.empty((0, channel_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_adap_left = tf.keras.models.load_model('final_model_left_WS80.h5')\n",
    "\n",
    "# # model_adap_left.summary()\n",
    "# for layer in model_adap_left.layers[:9]:\n",
    "#     layer.trainable = False\n",
    "# for layer in model_adap_left.layers:\n",
    "#     print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

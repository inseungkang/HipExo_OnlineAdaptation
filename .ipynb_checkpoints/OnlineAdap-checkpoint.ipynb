{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import keras\n",
    "from scipy.signal import find_peaks, peak_prominences, peak_widths\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "columns = ['lJPos', 'rJPos', 'lJVel', 'rJVel', 'lJTorque', 'rJTorque',\n",
    "           'eulerX', 'eulerY', 'eulerZ', 'gyroX', 'gyroY', 'gyroZ', 'accX', 'accY', 'accZ',\n",
    "           'batt', 'cpu', 'mem', 'lBttn', 'rBttn', 'time', 'lJVelFilt', 'rJVelFilt',\n",
    "           'lJPosReset', 'rJPosReset', 'lGC', 'rGC', 'stand', 'lCmdTorque', 'rCmdTorque',\n",
    "           'lRecvTorque', 'rRecvTorque', 'lStanceSwing', 'rStanceSwing', 'nWalk', 'lWalk', 'rWalk', 'none']\n",
    "\n",
    "ST_columns = ['lJPos', 'rJPos', 'lJVel', 'rJVel', 'lJTorque', 'rJTorque',\n",
    "           'eulerX', 'eulerY', 'eulerZ', 'gyroX', 'gyroY', 'gyroZ', 'accX', 'accY', 'accZ',\n",
    "           'lBttn', 'rBttn', 'time', 'lJVelFilt', 'rJVelFilt',\n",
    "           'lJPosReset', 'rJPosReset', 'lGC', 'rGC', 'stand', 'lCmdTorque', 'rCmdTorque',\n",
    "           'lRecvTorque', 'rRecvTorque', 'lStanceSwing', 'rStanceSwing', 'nWalk', 'lWalk', 'rWalk', 'none']\n",
    "\n",
    "channel = ['lJPos', 'rJPos', 'lJVel', 'rJVel', 'gyroX', 'gyroY', 'gyroZ', 'accX', 'accY', 'accZ', 'lWalk', 'rWalk']\n",
    "    \n",
    "def find_peak_idx(joint_positions):\n",
    "    peaks, _ = find_peaks(joint_positions)\n",
    "    prominences = peak_prominences(joint_positions, peaks)[0]\n",
    "    maximas, _ = find_peaks(joint_positions, prominence=np.median(prominences)+np.var(prominences), distance=150)\n",
    "    return maximas\n",
    "\n",
    "def label_ground_truth(joint_positions):\n",
    "    maximas = find_peak_idx(joint_positions)\n",
    "    maximas = np.append(0, maximas)\n",
    "    end_idx = maximas[-1]\n",
    "    \n",
    "    y = pd.Series(np.nan, index=range(0, joint_positions.shape[0]))  \n",
    "    for maxima in maximas:\n",
    "        y[maxima] = 1\n",
    "        y[maxima+1] = 0\n",
    "    y.interpolate(inplace=True)\n",
    "    y.fillna(0, inplace=True)\n",
    "    y_theta = y * 2 * np.pi\n",
    "    \n",
    "    cartesian_output = np.stack([np.cos(y_theta), np.sin(y_theta)], axis=1)\n",
    "    return y, end_idx, cartesian_output\n",
    "\n",
    "def custom_rmse(y_true, y_pred):\n",
    "    #Raw values and Prediction are in X,Y\n",
    "    labels, theta, gp = {}, {}, {}\n",
    "\n",
    "    #Separate legs\n",
    "    left_true = y_true[:, :2]\n",
    "    right_true = y_true[:, 2:]\n",
    "    left_pred = y_pred[:, :2]\n",
    "    right_pred = y_pred[:, 2:]\n",
    "    \n",
    "    #Calculate cosine distance\n",
    "    left_num = np.sum(np.multiply(left_true, left_pred), axis=1)\n",
    "    left_denom = np.linalg.norm(left_true, axis=1) * np.linalg.norm(left_pred, axis=1)\n",
    "    right_num = np.sum(np.multiply(right_true, right_pred), axis=1)\n",
    "    right_denom = np.linalg.norm(right_true, axis=1) * np.linalg.norm(right_pred, axis=1)\n",
    "\n",
    "    left_cos = left_num / left_denom\n",
    "    right_cos = right_num / right_denom\n",
    "    \n",
    "    #Clip large values and small values\n",
    "    left_cos = np.minimum(left_cos, np.zeros(left_cos.shape)+1)\n",
    "    left_cos = np.maximum(left_cos, np.zeros(left_cos.shape)-1)\n",
    "    \n",
    "    right_cos = np.minimum(right_cos, np.zeros(right_cos.shape)+1)\n",
    "    right_cos = np.maximum(right_cos, np.zeros(right_cos.shape)-1)\n",
    "    \n",
    "    # What if denominator is zero (model predicts 0 for both X and Y)\n",
    "    left_cos[np.isnan(left_cos)] = 0\n",
    "    right_cos[np.isnan(right_cos)] = 0\n",
    "    \n",
    "    #Get theta error\n",
    "    left_theta = np.arccos(left_cos)\n",
    "    right_theta = np.arccos(right_cos)\n",
    "    \n",
    "    #Get gait phase error\n",
    "    left_gp_error = left_theta * 100 / (2*np.pi)\n",
    "    right_gp_error = right_theta * 100 / (2*np.pi)\n",
    "    \n",
    "    #Get rmse\n",
    "    left_rmse = np.sqrt(np.mean(np.square(left_gp_error)))\n",
    "    right_rmse = np.sqrt(np.mean(np.square(right_gp_error)))\n",
    "\n",
    "    #Separate legs\n",
    "    labels['left_true'] = left_true\n",
    "    labels['right_true'] = right_true\n",
    "    labels['left_pred'] = left_pred\n",
    "    labels['right_pred'] = right_pred\n",
    "\n",
    "    for key, value in labels.items(): \n",
    "        #Convert to polar\n",
    "        theta[key] = np.arctan2(value[:, 1], value[:, 0])\n",
    "        \n",
    "        #Bring into range of 0 to 2pi\n",
    "        theta[key] = np.mod(theta[key] + 2*np.pi, 2*np.pi)\n",
    "\n",
    "        #Interpolate from 0 to 100%\n",
    "        gp[key] = 100*theta[key] / (2*np.pi)\n",
    "\n",
    "    return left_rmse, right_rmse\n",
    "\n",
    "def custom_rmse_uni(left_true, left_pred):\n",
    "    #Raw values and Prediction are in X,Y\n",
    "    labels, theta, gp = {}, {}, {}\n",
    "    \n",
    "    #Calculate cosine distance\n",
    "    left_num = np.sum(np.multiply(left_true, left_pred), axis=1)\n",
    "    left_denom = np.linalg.norm(left_true, axis=1) * np.linalg.norm(left_pred, axis=1)\n",
    "\n",
    "    left_cos = left_num / left_denom\n",
    "    \n",
    "    #Clip large values and small values\n",
    "    left_cos = np.minimum(left_cos, np.zeros(left_cos.shape)+1)\n",
    "    left_cos = np.maximum(left_cos, np.zeros(left_cos.shape)-1)\n",
    "    \n",
    "    # What if denominator is zero (model predicts 0 for both X and Y)\n",
    "    left_cos[np.isnan(left_cos)] = 0\n",
    "    \n",
    "    #Get theta error\n",
    "    left_theta = np.arccos(left_cos)\n",
    "    \n",
    "    #Get gait phase error\n",
    "    left_gp_error = left_theta * 100 / (2*np.pi)\n",
    "    \n",
    "    #Get rmse\n",
    "    left_rmse = np.sqrt(np.mean(np.square(left_gp_error)))\n",
    "\n",
    "    #Separate legs\n",
    "    labels['left_true'] = left_true\n",
    "    labels['left_pred'] = left_pred\n",
    "\n",
    "    for key, value in labels.items(): \n",
    "        #Convert to polar\n",
    "        theta[key] = np.arctan2(value[:, 1], value[:, 0])\n",
    "        \n",
    "        #Bring into range of 0 to 2pi\n",
    "        theta[key] = np.mod(theta[key] + 2*np.pi, 2*np.pi)\n",
    "\n",
    "        #Interpolate from 0 to 100%\n",
    "        gp[key] = 100*theta[key] / (2*np.pi)\n",
    "\n",
    "    return left_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "OA_columns = ['lJPos', 'rJPos', 'lJVel', 'rJVel', 'lJTorque', 'rJTorque',\n",
    "           'eulerX', 'eulerY', 'eulerZ', 'gyroX', 'gyroY', 'gyroZ', 'accX', 'accY', 'accZ',\n",
    "           'Battery', 'timestamp', 'noNeed1', 'noNeed2', 'noNeed3',\n",
    "           'noNeed4', 'lRandom', 'rRandom', 'lTorShape', 'rTorShape', 'lCmdTorque', 'rCmdTorque',\n",
    "           'lStance', 'rStance', 'lMode', 'rMode', 'nMode', 'lGP', 'rGP', 'none']\n",
    "\n",
    "# channel = ['lJPos', 'rJPos', 'lJVel', 'rJVel', 'gyroX', 'gyroY', 'gyroZ', 'accX', 'accY', 'accZ', 'lGP', 'rGP']\n",
    "channel = ['lJPos', 'rJPos', 'lJVel', 'rJVel', 'gyroX', 'gyroY', 'gyroZ', 'accX', 'accY', 'accZ']\n",
    "for file_path in glob.glob(f'data/OA_TEST_OVERGROUND.txt'):\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=1)\n",
    "    data.columns = OA_columns\n",
    "    input_data = pd.DataFrame(data, columns=channel).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 61, 10)            2010      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 61, 10)            40        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 61, 10)            0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 61, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 42, 10)            2010      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 42, 10)            40        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 42, 10)            0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 42, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 420)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 21)                8841      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 44        \n",
      "=================================================================\n",
      "Total params: 12,985\n",
      "Trainable params: 12,945\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "82/82 [==============================] - 0s 5ms/step - loss: 0.6840\n",
      "13.261957081031866, 24.035774436195634\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.6391\n",
      "4.316873383158028, 18.369322719900524\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6371\n",
      "3.8892535974247684, 26.207371842780013\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6355\n",
      "4.037625020888691, 26.249080802974586\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.6371\n",
      "3.975456675723497, 26.448461887247415\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.6356\n",
      "3.8606757224151975, 20.027117333265902\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6368\n",
      "3.6882583643297435, 22.246278082524427\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 0.6361\n",
      "4.858603637694288, 24.028283779997928\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6366\n",
      "4.49294005481404, 23.198180445949724\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6355\n",
      "3.9961222104068597, 19.98590902973045\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.6341\n",
      "3.854021095640314, 25.246183060475175\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.6350\n",
      "3.856820972927735, 26.620833418120554\n"
     ]
    }
   ],
   "source": [
    "model_adap_left = keras.models.load_model('final_model_left_WS80.h5')\n",
    "model_stat_left = keras.models.load_model('final_model_left_WS80.h5')\n",
    "\n",
    "# model_adap_left.summary()\n",
    "# for layer in model_adap_left.layers[:8]:\n",
    "#     layer.trainable = False\n",
    "#     print(layer.trainable)\n",
    "\n",
    "channel_number = 10\n",
    "buffer_size = 3000\n",
    "\n",
    "old_buffer = np.empty((0, channel_number))\n",
    "current_buffer = np.empty((0, channel_number))\n",
    "\n",
    "for ii, stream_vec in enumerate(input_data):\n",
    "    stream_vec = np.expand_dims(stream_vec, axis=0)\n",
    "    current_buffer = np.concatenate([current_buffer, stream_vec], axis=0)\n",
    "        \n",
    "    if current_buffer.shape[0] == buffer_size:\n",
    "        peak_idx = find_peak_idx(current_buffer[:,0])[-1]\n",
    "        \n",
    "        x = np.concatenate([old_buffer, current_buffer[:peak_idx, :]], axis=0)\n",
    "#         l_mode = x[:,-2] \n",
    "#         x = x[:,:-2]\n",
    "\n",
    "        gait_phase, end_idx, y = label_ground_truth(x[:,0])\n",
    "        x = x[:end_idx,:]\n",
    "        y = y[:end_idx,:]      \n",
    "#         gait_phase = gait_phase[:end_idx]\n",
    "#         l_mode = l_mode[:end_idx]\n",
    "        \n",
    "#         new_idx = np.where((l_mode != 0))[0].tolist()\n",
    "#         x = x[new_idx,:]\n",
    "#         y = y[new_idx,:]\n",
    "#         gait_phase = gait_phase[new_idx]\n",
    "#         l_mode = l_mode[new_idx]\n",
    "        \n",
    "#         plt.plot(x[:,0])\n",
    "#         plt.plot(gait_phase)\n",
    "#         plt.plot(l_mode)\n",
    "#         plt.show()\n",
    "        \n",
    "        window_size = 80\n",
    "        shape = (x.shape[0] - window_size + 1, window_size, x.shape[1])\n",
    "        strides = (x.strides[0], x.strides[0], x.strides[1])\n",
    "        x = np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)\n",
    "        y = np.expand_dims(y[window_size - 1:], axis=1)\n",
    "        \n",
    "        model_adap_left.fit(x, y, epochs=1, verbose=1)\n",
    "        \n",
    "        y_new_test = model_adap_left.predict(x)\n",
    "        y_old_test = model_stat_left.predict(x)\n",
    "        y = np.squeeze(y, axis=1)\n",
    "    \n",
    "        left_rmse_o = custom_rmse_uni(y, y_old_test)\n",
    "        left_rmse_n = custom_rmse_uni(y, y_new_test)\n",
    "        print(str(left_rmse_o)+\", \"+str(left_rmse_n))\n",
    "        \n",
    "#         plt.plot(y[:,1])\n",
    "#         plt.plot(y_old_test[:,1])\n",
    "#         plt.plot(y_new_test[:,1])\n",
    "#         plt.show()\n",
    "        \n",
    "        old_buffer = current_buffer[peak_idx:, :]\n",
    "        current_buffer = np.empty((0, channel_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model_adap_left = keras.models.load_model('final_model_left_WS80.h5')\n",
    "\n",
    "# model_adap_left.summary()\n",
    "for layer in model_adap_left.layers[:9]:\n",
    "    layer.trainable = False\n",
    "for layer in model_adap_left.layers:\n",
    "    print(layer.trainable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
